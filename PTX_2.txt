# Compilation provided by Compiler Explorer at https://godbolt.org/
.visible .entry _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j(
        .param .align 8 .b8 _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_0[32],
        .param .align 4 .b8 _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_1[12],
        .param .align 4 .b8 _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_2[12],
        .param .align 4 .b8 _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_3[12],
        .param .u32 _Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_4
)
{

        ld.param.u64    %rd4, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_0+24];
        ld.param.u64    %rd2, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_0+8];
        ld.param.u64    %rd1, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_0];
        ld.param.u32    %r6, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_1+8];
        ld.param.u32    %r5, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_1+4];
        ld.param.u32    %r4, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_1];
        ld.param.f32    %f1, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_2];
        ld.param.f32    %f2, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_2+4];
        ld.param.f32    %f3, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_2+8];
        ld.param.f32    %f4, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_3];
        ld.param.f32    %f5, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_3+4];
        ld.param.f32    %f6, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_3+8];
        ld.param.u32    %r7, [_Z18d_simplex_3d_float14cudaPitchedPtr5uint36float3S1_j_param_4];
        mov.u32         %r8, %ntid.x;
        mov.u32         %r9, %ctaid.x;
        mov.u32         %r10, %tid.x;
        mad.lo.s32      %r1, %r8, %r9, %r10;
        mov.u32         %r11, %ntid.y;
        mov.u32         %r12, %ctaid.y;
        mov.u32         %r13, %tid.y;
        mad.lo.s32      %r2, %r11, %r12, %r13;
        mov.u32         %r14, %ntid.z;
        mov.u32         %r15, %ctaid.z;
        mov.u32         %r16, %tid.z;
        mad.lo.s32      %r3, %r14, %r15, %r16;
        mov.pred        %p39, -1;
        setp.ge.u32     %p4, %r1, %r4;
        @%p4 bra        BB0_2;

        setp.ge.u32     %p39, %r2, %r5;

        setp.ge.u32     %p5, %r3, %r6;
        or.pred         %p6, %p39, %p5;
        @%p6 bra        BB0_4;

        cvt.rn.f32.u32  %f7, %r1;
        fma.rn.f32      %f8, %f4, %f7, %f1;
        cvt.rn.f32.u32  %f9, %r2;
        fma.rn.f32      %f10, %f5, %f9, %f2;
        cvt.rn.f32.u32  %f11, %r3;
        fma.rn.f32      %f12, %f6, %f11, %f3;
        add.f32         %f13, %f8, %f10;
        add.f32         %f14, %f13, %f12;
        fma.rn.f32      %f15, %f14, 0f3EAAAAAB, %f8;
        cvt.rmi.f32.f32 %f16, %f15;
        fma.rn.f32      %f17, %f14, 0f3EAAAAAB, %f10;
        cvt.rmi.f32.f32 %f18, %f17;
        fma.rn.f32      %f19, %f14, 0f3EAAAAAB, %f12;
        cvt.rmi.f32.f32 %f20, %f19;
        add.f32         %f21, %f16, %f18;
        add.f32         %f22, %f21, %f20;
        sub.f32         %f23, %f8, %f16;
        fma.rn.f32      %f24, %f22, 0f3E2AAAAB, %f23;
        sub.f32         %f25, %f10, %f18;
        fma.rn.f32      %f26, %f22, 0f3E2AAAAB, %f25;
        sub.f32         %f27, %f12, %f20;
        fma.rn.f32      %f28, %f22, 0f3E2AAAAB, %f27;
        setp.ge.f32     %p7, %f24, %f26;
        setp.ge.f32     %p8, %f24, %f28;
        setp.ge.f32     %p9, %f26, %f28;
        and.pred        %p10, %p7, %p8;
        selp.u32        %r17, 1, 0, %p10;
        cvt.rn.f32.s32  %f29, %r17;
        or.pred         %p11, %p7, %p8;
        selp.u32        %r18, 1, 0, %p11;
        cvt.rn.f32.s32  %f30, %r18;
        setp.ltu.f32    %p12, %f24, %f26;
        or.pred         %p13, %p12, %p9;
        and.pred        %p14, %p12, %p9;
        setp.ltu.f32    %p15, %f26, %f28;
        selp.u32        %r19, 1, 0, %p14;
        cvt.rn.f32.s32  %f31, %r19;
        selp.u32        %r20, 1, 0, %p13;
        cvt.rn.f32.s32  %f32, %r20;
        setp.ltu.f32    %p16, %f24, %f28;
        or.pred         %p17, %p16, %p15;
        and.pred        %p18, %p16, %p15;
        selp.u32        %r21, 1, 0, %p18;
        cvt.rn.f32.s32  %f33, %r21;
        selp.u32        %r22, 1, 0, %p17;
        cvt.rn.f32.s32  %f34, %r22;
        sub.f32         %f35, %f24, %f29;
        add.f32         %f36, %f35, 0f3E2AAAAB;
        sub.f32         %f37, %f26, %f31;
        add.f32         %f38, %f37, 0f3E2AAAAB;
        sub.f32         %f39, %f28, %f33;
        add.f32         %f40, %f39, 0f3E2AAAAB;
        sub.f32         %f41, %f24, %f30;
        add.f32         %f42, %f41, 0f3EAAAAAB;
        sub.f32         %f43, %f26, %f32;
        add.f32         %f44, %f43, 0f3EAAAAAB;
        sub.f32         %f45, %f28, %f34;
        add.f32         %f46, %f45, 0f3EAAAAAB;
        add.f32         %f47, %f24, 0fBF800000;
        add.f32         %f48, %f47, 0f3F000000;
        add.f32         %f49, %f26, 0fBF800000;
        add.f32         %f50, %f49, 0f3F000000;
        add.f32         %f51, %f28, 0fBF800000;
        add.f32         %f52, %f51, 0f3F000000;
        mul.f32         %f53, %f24, %f24;
        mov.f32         %f54, 0f3F000000;
        sub.f32         %f55, %f54, %f53;
        mul.f32         %f56, %f26, %f26;
        sub.f32         %f57, %f55, %f56;
        mul.f32         %f58, %f28, %f28;
        sub.f32         %f59, %f57, %f58;
        setp.lt.f32     %p19, %f59, 0f00000000;
        selp.f32        %f60, 0f00000000, %f59, %p19;
        mul.f32         %f61, %f60, %f60;
        mul.f32         %f62, %f60, %f61;
        mul.f32         %f63, %f60, %f62;
        mov.b32          %r23, %f16;
        mul.lo.s32      %r24, %r23, 73856093;
        mov.b32          %r25, %f18;
        mul.lo.s32      %r26, %r25, 19349663;
        mov.b32          %r27, %f20;
        mul.lo.s32      %r28, %r27, 83492791;
        xor.b32         %r29, %r24, %r7;
        xor.b32         %r30, %r29, %r26;
        xor.b32         %r31, %r30, %r28;
        and.b32         %r32, %r31, -2147483648;
        shl.b32         %r33, %r31, 3;
        and.b32         %r34, %r33, -2147483648;
        shr.u32         %r35, %r31, 4;
        mul.lo.s32      %r36, %r35, 3;
        shr.u32         %r37, %r36, 28;
        setp.eq.s32     %p20, %r37, 0;
        setp.ne.s32     %p21, %r37, 0;
        setp.ne.s32     %p22, %r37, 1;
        and.pred        %p23, %p22, %p21;
        selp.f32        %f64, %f26, %f28, %p23;
        selp.f32        %f65, %f26, %f24, %p20;
        mov.b32          %r38, %f65;
        mov.b32          %r39, %f64;
        xor.b32         %r40, %r38, %r32;
        mov.b32          %f66, %r40;
        xor.b32         %r41, %r39, %r34;
        mov.b32          %f67, %r41;
        add.f32         %f68, %f67, %f66;
        mul.f32         %f69, %f36, %f36;
        sub.f32         %f70, %f54, %f69;
        mul.f32         %f71, %f38, %f38;
        sub.f32         %f72, %f70, %f71;
        mul.f32         %f73, %f40, %f40;
        sub.f32         %f74, %f72, %f73;
        setp.lt.f32     %p24, %f74, 0f00000000;
        selp.f32        %f75, 0f00000000, %f74, %p24;
        mul.f32         %f76, %f75, %f75;
        mul.f32         %f77, %f75, %f76;
        mul.f32         %f78, %f75, %f77;
        add.f32         %f79, %f16, %f29;
        add.f32         %f80, %f18, %f31;
        add.f32         %f81, %f20, %f33;
        mov.b32          %r42, %f79;
        mul.lo.s32      %r43, %r42, 73856093;
        mov.b32          %r44, %f80;
        mul.lo.s32      %r45, %r44, 19349663;
        mov.b32          %r46, %f81;
        mul.lo.s32      %r47, %r46, 83492791;
        xor.b32         %r48, %r43, %r7;
        xor.b32         %r49, %r48, %r45;
        xor.b32         %r50, %r49, %r47;
        and.b32         %r51, %r50, -2147483648;
        shl.b32         %r52, %r50, 3;
        and.b32         %r53, %r52, -2147483648;
        shr.u32         %r54, %r50, 4;
        mul.lo.s32      %r55, %r54, 3;
        shr.u32         %r56, %r55, 28;
        setp.eq.s32     %p25, %r56, 0;
        selp.f32        %f82, %f38, %f36, %p25;
        mov.b32          %r57, %f82;
        setp.ne.s32     %p26, %r56, 0;
        setp.ne.s32     %p27, %r56, 1;
        and.pred        %p28, %p27, %p26;
        selp.f32        %f83, %f38, %f40, %p28;
        mov.b32          %r58, %f83;
        xor.b32         %r59, %r57, %r51;
        mov.b32          %f84, %r59;
        xor.b32         %r60, %r58, %r53;
        mov.b32          %f85, %r60;
        add.f32         %f86, %f84, %f85;
        mul.f32         %f87, %f78, %f86;
        mul.f32         %f88, %f42, %f42;
        sub.f32         %f89, %f54, %f88;
        mul.f32         %f90, %f44, %f44;
        sub.f32         %f91, %f89, %f90;
        mul.f32         %f92, %f46, %f46;
        sub.f32         %f93, %f91, %f92;
        setp.lt.f32     %p29, %f93, 0f00000000;
        selp.f32        %f94, 0f00000000, %f93, %p29;
        mul.f32         %f95, %f94, %f94;
        mul.f32         %f96, %f94, %f95;
        mul.f32         %f97, %f94, %f96;
        add.f32         %f98, %f16, %f30;
        add.f32         %f99, %f18, %f32;
        add.f32         %f100, %f20, %f34;
        mov.b32          %r61, %f98;
        mul.lo.s32      %r62, %r61, 73856093;
        mov.b32          %r63, %f99;
        mul.lo.s32      %r64, %r63, 19349663;
        mov.b32          %r65, %f100;
        mul.lo.s32      %r66, %r65, 83492791;
        xor.b32         %r67, %r62, %r7;
        xor.b32         %r68, %r67, %r64;
        xor.b32         %r69, %r68, %r66;
        and.b32         %r70, %r69, -2147483648;
        shl.b32         %r71, %r69, 3;
        and.b32         %r72, %r71, -2147483648;
        shr.u32         %r73, %r69, 4;
        mul.lo.s32      %r74, %r73, 3;
        shr.u32         %r75, %r74, 28;
        setp.eq.s32     %p30, %r75, 0;
        selp.f32        %f101, %f44, %f42, %p30;
        mov.b32          %r76, %f101;
        setp.ne.s32     %p31, %r75, 0;
        setp.ne.s32     %p32, %r75, 1;
        and.pred        %p33, %p32, %p31;
        selp.f32        %f102, %f44, %f46, %p33;
        mov.b32          %r77, %f102;
        xor.b32         %r78, %r76, %r70;
        mov.b32          %f103, %r78;
        xor.b32         %r79, %r77, %r72;
        mov.b32          %f104, %r79;
        add.f32         %f105, %f103, %f104;
        mul.f32         %f106, %f48, %f48;
        sub.f32         %f107, %f54, %f106;
        mul.f32         %f108, %f50, %f50;
        sub.f32         %f109, %f107, %f108;
        mul.f32         %f110, %f52, %f52;
        sub.f32         %f111, %f109, %f110;
        setp.lt.f32     %p34, %f111, 0f00000000;
        selp.f32        %f112, 0f00000000, %f111, %p34;
        mul.f32         %f113, %f112, %f112;
        mul.f32         %f114, %f112, %f113;
        mul.f32         %f115, %f112, %f114;
        add.f32         %f116, %f16, 0f3F800000;
        add.f32         %f117, %f18, 0f3F800000;
        add.f32         %f118, %f20, 0f3F800000;
        mov.b32          %r80, %f116;
        mul.lo.s32      %r81, %r80, 73856093;
        mov.b32          %r82, %f117;
        mul.lo.s32      %r83, %r82, 19349663;
        mov.b32          %r84, %f118;
        mul.lo.s32      %r85, %r84, 83492791;
        xor.b32         %r86, %r81, %r7;
        xor.b32         %r87, %r86, %r83;
        xor.b32         %r88, %r87, %r85;
        and.b32         %r89, %r88, -2147483648;
        shl.b32         %r90, %r88, 3;
        and.b32         %r91, %r90, -2147483648;
        shr.u32         %r92, %r88, 4;
        mul.lo.s32      %r93, %r92, 3;
        shr.u32         %r94, %r93, 28;
        setp.eq.s32     %p35, %r94, 0;
        selp.f32        %f119, %f50, %f48, %p35;
        mov.b32          %r95, %f119;
        setp.ne.s32     %p36, %r94, 0;
        setp.ne.s32     %p37, %r94, 1;
        and.pred        %p38, %p37, %p36;
        selp.f32        %f120, %f50, %f52, %p38;
        mov.b32          %r96, %f120;
        xor.b32         %r97, %r95, %r89;
        mov.b32          %f121, %r97;
        xor.b32         %r98, %r96, %r91;
        mov.b32          %f122, %r98;
        add.f32         %f123, %f121, %f122;
        fma.rn.f32      %f124, %f63, %f68, %f87;
        fma.rn.f32      %f125, %f97, %f105, %f124;
        fma.rn.f32      %f126, %f115, %f123, %f125;
        mul.f32         %f127, %f126, 0f42980000;
        cvt.u64.u32     %rd5, %r3;
        mul.lo.s64      %rd6, %rd5, %rd4;
        cvt.u64.u32     %rd7, %r2;
        add.s64         %rd8, %rd6, %rd7;
        mul.lo.s64      %rd9, %rd8, %rd2;
        cvt.u64.u32     %rd10, %r1;
        add.s64         %rd11, %rd9, %rd10;
        cvta.to.global.u64      %rd12, %rd1;
        shl.b64         %rd13, %rd11, 2;
        add.s64         %rd14, %rd12, %rd13;
        st.global.f32   [%rd14], %f127;

        ret;
}
